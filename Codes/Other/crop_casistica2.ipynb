{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definizione delle funzioni di identificazione dei bordi, identificazione dei bordi opposti e di crop+resize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "def load_image(file):\n",
    "    img = Image.open(file)\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "def save_image(img, file):\n",
    "    img = Image.fromarray(img, mode='L')\n",
    "    img.save(file)\n",
    "\n",
    "def findBorders(t2w):\n",
    "    # Make t2w boolean\n",
    "    canale_bw = t2w > 0\n",
    "    # Find non-black rows and columns\n",
    "    rows = np.any(canale_bw, axis=1)\n",
    "    cols = np.any(canale_bw, axis=0)\n",
    "    # Get first and last non-black row and column indexes\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]] if np.any(rows) else (0, t2w.shape[0])\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]] if np.any(cols) else (0, t2w.shape[1])\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def findBordersOpposite(adc, rmin, rmax, cmin, cmax):\n",
    "    # Calculate opposite coordinates for cropping\n",
    "    opp_rmin = adc.shape[0] - rmax\n",
    "    opp_rmax = adc.shape[0] - rmin\n",
    "    opp_cmin = adc.shape[1] - cmax\n",
    "    opp_cmax = adc.shape[1] - cmin\n",
    "    return opp_rmin, opp_rmax, opp_cmin, opp_cmax\n",
    "\n",
    "def cropResizeImages(adc, hbv, t2w, mask):\n",
    "    # Get original image size\n",
    "    original_shape = t2w.shape\n",
    "    \n",
    "    # Find black borders in t2w channel\n",
    "    rmin_t2w, rmax_t2w, cmin_t2w, cmax_t2w = findBorders(t2w)\n",
    "    \n",
    "    # Calculate opposite borders for adc and hbv\n",
    "    rmin_adc, rmax_adc, cmin_adc, cmax_adc = findBordersOpposite(adc, rmin_t2w, rmax_t2w, cmin_t2w, cmax_t2w)\n",
    "    \n",
    "    # Crop t2w\n",
    "    t2w_cropped = t2w[rmin_t2w:rmax_t2w, cmin_t2w:cmax_t2w]\n",
    "    mask_cropped = mask[rmin_t2w:rmax_t2w, cmin_t2w:cmax_t2w]\n",
    "    \n",
    "    # Crop adc and hbv at opposite borders\n",
    "    adc_cropped = adc[rmin_adc:rmax_adc, cmin_adc:cmax_adc]\n",
    "    hbv_cropped = hbv[rmin_adc:rmax_adc, cmin_adc:cmax_adc]\n",
    "    \n",
    "    cropped_shape = t2w_cropped.shape\n",
    "    \n",
    "    # RESIZE IMAGES\n",
    "    # Resize cropped images to the original shape\n",
    "    resizeShape = t2w.shape\n",
    "    adc_cropped_resized = np.array(Image.fromarray(adc_cropped, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
    "    hbv_cropped_resized = np.array(Image.fromarray(hbv_cropped, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
    "    t2w_cropped_resized = np.array(Image.fromarray(t2w_cropped, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
    "    mask_cropped_resized = np.array(Image.fromarray(mask_cropped, mode='L').resize(resizeShape, Image.NEAREST), dtype=np.uint8)\n",
    "    \n",
    "    # Create a dictionary to store crop metadata\n",
    "    # cropMetadata = {\n",
    "    #     't2w_start_x': cmin_t2w, 't2w_start_y': rmin_t2w, 't2w_end_x': cmax_t2w, 't2w_end_y': rmax_t2w,\n",
    "    #     'adc_start_x': cmin_adc, 'adc_start_y': rmin_adc, 'adc_end_x': cmax_adc, 'adc_end_y': rmax_adc,\n",
    "    #     'cropDimension': min(rmax_t2w - rmin_t2w, cmax_t2w - cmin_t2w),\n",
    "    #     'cropped_shape': cropped_shape,\n",
    "    #     'original_shape': original_shape,\n",
    "    #     'resizeShape': resizeShape,\n",
    "    #     'flagCrop': True\n",
    "    # }\n",
    "    \n",
    "    return adc_cropped_resized, hbv_cropped_resized, t2w_cropped_resized, mask_cropped_resized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applicazione del crop ai pazienti rientranti nella casistica 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path in cui sono presenti le cartelle dei pazienti\n",
    "pathDataset = os.path.join(\".\", \"PAZIENTI CASISTICA 2\")\n",
    "\n",
    "# Loop sui pazienti della casistica 2\n",
    "for paziente in tqdm(os.listdir(pathDataset)):\n",
    "    pathPaziente = os.path.join(pathDataset, paziente)\n",
    "    # Loop sulle slice di un paziente della casistica 2\n",
    "    for slice in os.listdir(os.path.join(pathPaziente, \"adc\")):\n",
    "        # Load delle immagini\n",
    "        adc = load_image(os.path.join(pathPaziente, \"adc\", slice))\n",
    "        hbv = load_image(os.path.join(pathPaziente, \"hbv\", slice))\n",
    "        t2w = load_image(os.path.join(pathPaziente, \"t2w\", slice))\n",
    "        mask = load_image(os.path.join(pathPaziente, \"manual\", slice))\n",
    "        # Crop e resize delle immagini\n",
    "        adc_cropped_resized, hbv_cropped_resized, t2w_cropped_resized, mask_cropped_resized = cropResizeImages(adc, hbv, t2w, mask)\n",
    "        # Creazione dell'immagine stacked\n",
    "        stacked = np.stack([adc_cropped_resized, hbv_cropped_resized, t2w_cropped_resized], axis=-1)\n",
    "        # Salvataggio delle nuove immagini\n",
    "        save_image(adc_cropped_resized, os.path.join(pathPaziente, \"adc\", slice))\n",
    "        save_image(hbv_cropped_resized, os.path.join(pathPaziente, \"hbv\", slice))\n",
    "        save_image(t2w_cropped_resized, os.path.join(pathPaziente, \"t2w\", slice))\n",
    "        save_image(mask_cropped_resized, os.path.join(pathPaziente, \"manual\", slice))\n",
    "        stacked = Image.fromarray(stacked, mode='RGB')\n",
    "        stacked.save(os.path.join(pathPaziente, \"stacked\", slice))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

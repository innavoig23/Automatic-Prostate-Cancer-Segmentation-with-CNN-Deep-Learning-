{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definizione delle funzioni di identificazione dei bordi e di crop+resize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_image(file):\n",
    "    img = Image.open(file)\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "def save_image(img, file):\n",
    "    img = Image.fromarray(img, mode='L')\n",
    "    img.save(file)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "def findBorders(adc):\n",
    "    # FIND BLACK BORDERS IN T2W CHANNEL\n",
    "    # Make t2w boolean\n",
    "    canale_bw = adc > 0\n",
    "    # Find non-black rows and columns\n",
    "    rows = np.any(canale_bw, axis=1)\n",
    "    cols = np.any(canale_bw, axis=0)\n",
    "    # Get first and last non-black row and column indexes\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]] if np.any(rows) else (0, adc.shape[0])\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]] if np.any(cols) else (0, adc.shape[1])\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def cropResizeImages(adc, hbv, t2w, mask):\n",
    "    # CROP IMAGES\n",
    "    # Get original image size\n",
    "    original_shape = t2w.shape\n",
    "    # Find black borders in t2w channel\n",
    "    rmin_adc, rmax_adc, cmin_adc, cmax_adc = findBorders(adc)\n",
    "    # Get final cropped image size\n",
    "    cropDimension = min(rmax_adc - rmin_adc, cmax_adc - cmin_adc)\n",
    "    if cropDimension % 2 != 0: # ensure crop_size is even\n",
    "        cropDimension -= 1\n",
    "    # La parte sotto è commentata perchè in questo caso il crop deve essere sempre fatto (e verrà sicuramente fatto)\n",
    "    \n",
    "    # if abs(t2w.shape[0] - cropDimension) < 5: # do not crop if the black region is too small\n",
    "    #     cropDimension = t2w.shape[0]\n",
    "    #     flagCrop = False\n",
    "    #     # resize images to 256x256\n",
    "    #     resizeShape = t2w.shape\n",
    "    #     adc_resized = np.array(Image.fromarray(adc, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
    "    #     hbv_resized = np.array(Image.fromarray(hbv, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
    "    #     t2w_resized = np.array(Image.fromarray(t2w, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
    "    #     mask_resized = np.array(Image.fromarray(mask, mode='L').resize(resizeShape, Image.NEAREST), dtype=np.uint8)\n",
    "    #     # Create the dictionary to store resize metadata\n",
    "    #     cropMetadata = {'flagCrop': flagCrop, 'original_shape': original_shape, 'resizeShape': resizeShape}\n",
    "    #     return adc_resized, hbv_resized, t2w_resized, cropMetadata\n",
    "    # else:\n",
    "    #     flagCrop = True\n",
    "    flagCrop = True\n",
    "    # Get center of the non-black region\n",
    "    center_x = (cmin_adc + cmax_adc) // 2\n",
    "    center_y = (rmin_adc + rmax_adc) // 2\n",
    "    # Get start and end coordinates for cropping\n",
    "    start_x = max(center_x - cropDimension // 2, 0)\n",
    "    start_y = max(center_y - cropDimension // 2, 0)\n",
    "    end_x = min(start_x + cropDimension, adc.shape[1])\n",
    "    end_y = min(start_y + cropDimension, adc.shape[0])\n",
    "\n",
    "    # Crop images at the center of the non-black region\n",
    "    adc_cropped = adc[start_y:end_y, start_x:end_x]\n",
    "    hbv_cropped = hbv[start_y:end_y, start_x:end_x]\n",
    "    t2w_cropped = t2w[start_y:end_y, start_x:end_x]\n",
    "    mask = mask[start_y:end_y, start_x:end_x]\n",
    "\n",
    "    cropped_shape = t2w_cropped.shape\n",
    "\n",
    "    # RESIZE IMAGES\n",
    "    resizeShape = t2w.shape\n",
    "    adc_cropped_resized = np.array(Image.fromarray(adc_cropped, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
    "    hbv_cropped_resized = np.array(Image.fromarray(hbv_cropped, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
    "    t2w_cropped_resized = np.array(Image.fromarray(t2w_cropped, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
    "    mask_cropped_resized = np.array(Image.fromarray(mask, mode='L').resize(resizeShape, Image.NEAREST), dtype=np.uint8)\n",
    "    # Create a dictionary to store crop metadata\n",
    "    # cropMetadata = {'start_x': start_x, 'start_y': start_y, 'end_x': end_x, 'end_y': end_y, 'cropDimension': cropDimension, 'cropped_shape': cropped_shape, 'center_x': center_x, 'center_y': center_y, 'original_shape': original_shape, 'resizeShape': resizeShape, 'flagCrop': flagCrop}\n",
    "\n",
    "    return adc_cropped_resized, hbv_cropped_resized, mask_cropped_resized\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applicazione del crop ai pazienti rientranti nella casistica 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path in cui sono presenti le cartelle dei pazienti\n",
    "pathDataset = os.path.join(\".\", \"PAZIENTI CASISTICA 3\")\n",
    "\n",
    "# Loop sui pazienti della casistica 3\n",
    "for paziente in tqdm(os.listdir(pathDataset)):\n",
    "    pathPaziente = os.path.join(pathDataset, paziente)\n",
    "    # Loop sulle slice di un paziente della casistica 2\n",
    "    for slice in os.listdir(os.path.join(pathPaziente, \"adc\")):\n",
    "        # Load delle immagini\n",
    "        adc = load_image(os.path.join(pathPaziente, \"adc\", slice))\n",
    "        hbv = load_image(os.path.join(pathPaziente, \"hbv\", slice))\n",
    "        t2w = load_image(os.path.join(pathPaziente, \"t2w\", slice))\n",
    "        mask = load_image(os.path.join(pathPaziente, \"manual\", slice))\n",
    "        # Crop e resize delle immagini\n",
    "        adc_cropped_resized, hbv_cropped_resized, mask_cropped_resized = cropResizeImages(adc, hbv, t2w, mask)\n",
    "        # Creazione dell'immagine stacked\n",
    "        stacked = np.stack([adc_cropped_resized, hbv_cropped_resized, t2w], axis=-1)\n",
    "        # Salvataggio delle nuove immagini\n",
    "        save_image(adc_cropped_resized, os.path.join(pathPaziente, \"adc\", slice))\n",
    "        save_image(hbv_cropped_resized, os.path.join(pathPaziente, \"hbv\", slice))\n",
    "        save_image(mask_cropped_resized, os.path.join(pathPaziente, \"manual\", slice))\n",
    "        stacked = Image.fromarray(stacked, mode='RGB')\n",
    "        stacked.save(os.path.join(pathPaziente, \"stacked\", slice))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

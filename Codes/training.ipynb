{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vRe49IHETYU"
      },
      "source": [
        "## **Initialization**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6imHqwasm04Q"
      },
      "source": [
        "**Google Drive Mount**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVsOw0y8m04T",
        "outputId": "a0940179-45cd-4c49-9283-6384cd8a14bb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5ChaChlFK3F"
      },
      "source": [
        "**Libraries Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1CT6100FK3F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import skimage.util as util\n",
        "import skimage.io as img\n",
        "from skimage import exposure\n",
        "from tqdm import tqdm\n",
        "from zipfile import ZipFile\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejUFAHnam04U"
      },
      "source": [
        "**Paths Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8lbufTHm04U"
      },
      "outputs": [],
      "source": [
        "# Work folder\n",
        "main_folder = \"/content/drive/MyDrive/Colab Notebooks/Progetto EIM/\"\n",
        "script_folder = main_folder\n",
        "\n",
        "# Path of the images dataset (already divided into train, val and test set and organized specifically for the architecture of MMSegmentation)\n",
        "# The zip is created in VSCode to avoid the need to reorganize the dataset every time the notebook is restarted and to get a faster execution\n",
        "zip_file_path_sets = \"/content/drive/MyDrive/Progetto EIM/ConstrAndTestSet_ForMMSegmentation.zip\"\n",
        "\n",
        "extract_folder_sets = \"/content/ProstateMRI/\"\n",
        "os.makedirs(extract_folder_sets, exist_ok=True)\n",
        "ProstateMRI_dataset_folder = extract_folder_sets\n",
        "\n",
        "# Folder for saving MMSegmentation results\n",
        "results_folder = \"/content/results_mmseg/\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofVw913aFK3F"
      },
      "source": [
        "**Zip Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4arYRzSBm04V",
        "outputId": "6028a6f7-0fc1-451f-9cf9-3bc2fcd193f9"
      },
      "outputs": [],
      "source": [
        "# Extracting zip file containing images from zip located at zip_file_path_sets\n",
        "with ZipFile(zip_file_path_sets, 'r') as zip_ref:\n",
        "    # Get the total number of files in the zip file\n",
        "    total_files = len(zip_ref.infolist())\n",
        "\n",
        "    # Create a progress bar using tqdm\n",
        "    with tqdm(total=total_files, unit=\"file\") as pbar:\n",
        "        for member in zip_ref.infolist():\n",
        "            # Extract each file individually and update the progress bar\n",
        "            zip_ref.extract(member, extract_folder_sets)\n",
        "            pbar.update(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2CmmS9DW8Ye"
      },
      "source": [
        "**MMSegmentation Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLd2Iblnm04V",
        "outputId": "e0730790-0d87-4cd9-b6b2-c14e9da1a23d"
      },
      "outputs": [],
      "source": [
        "# N.B ::: These are the basic installs needed for mmsegmentation, add the ones you need to run your script being careful about the dependencies\n",
        "\n",
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version\n",
        "\n",
        "# Install PyTorch\n",
        "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "# Install mmcv\n",
        "!pip install mmcv==2.0.0rc4 -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/index.html\n",
        "# Install mmsegmentation\n",
        "!pip install mmsegmentation\n",
        "# Install mmengine\n",
        "!pip install mmengine\n",
        "\n",
        "# Other installs\n",
        "!pip install ftfy\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8E4UmHT8sii"
      },
      "outputs": [],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMSegmentation installation\n",
        "import mmseg\n",
        "print(mmseg.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhjjbM02m04W"
      },
      "source": [
        "**Libraries Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3wB3yI38sij"
      },
      "outputs": [],
      "source": [
        "# Required imports definition (put all imports you need in this cell)\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from mmseg.apis import init_model, inference_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from mmengine import Config\n",
        "\n",
        "from mmseg.registry import DATASETS\n",
        "from mmseg.datasets import BaseSegDataset\n",
        "\n",
        "from skimage import morphology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qpky6Aam04W"
      },
      "source": [
        "**ProstateMRI Dataset Class Creation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrYqyjDO8xoa"
      },
      "outputs": [],
      "source": [
        "# Example of Dataset configuration, can be edited based on your strategy, make sure it's coherent with your config file\n",
        "\n",
        "classes = ('background',\n",
        "        'tumor')\n",
        "\n",
        "paletteProstate = [\n",
        "    (0, 0, 0), # background - black\n",
        "    (255, 255, 255), # tumor - white\n",
        "]\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class ProstateMRI(BaseSegDataset):\n",
        "    METAINFO = dict(classes = classes, palette = paletteProstate)\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(img_suffix='.png',\n",
        "                        seg_map_suffix='.png',\n",
        "                        reduce_zero_label = False,\n",
        "                        **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTZzE6XBm04W"
      },
      "source": [
        "**Load of config file for MMSegmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9dzPonQm04W"
      },
      "outputs": [],
      "source": [
        "# Path of the config file\n",
        "cfg_path = script_folder + 'config_FUNZIONANTE.py'\n",
        "\n",
        "# Load of the config file\n",
        "cfg = Config.fromfile(cfg_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRrDyn_Nm04W"
      },
      "source": [
        "**Selection of folders containing images of train, val and test sets and manual masks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih4kxndW9buw"
      },
      "outputs": [],
      "source": [
        "cfg.train_dataloader['dataset']['data_prefix'] = dict(img_path='stacked_dir/train/', seg_map_path='ann_dir/train/')\n",
        "cfg.val_dataloader['dataset']['data_prefix'] = dict(img_path='stacked_dir/val/', seg_map_path='ann_dir/val/')\n",
        "cfg.test_dataloader['dataset']['data_prefix'] = dict(img_path='stacked_dir/test/', seg_map_path='ann_dir/test/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ_VzcC_m04W"
      },
      "source": [
        "**Default Hyperparameters Modification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKHmfoRMhdY6"
      },
      "outputs": [],
      "source": [
        "cfg.compile=False\n",
        "\n",
        "cfg.data_root = ProstateMRI_dataset_folder\n",
        "cfg.save_dir = results_folder\n",
        "cfg.work_dir = results_folder\n",
        "\n",
        "cfg.train_dataloader['dataset']['data_root'] = ProstateMRI_dataset_folder\n",
        "cfg.val_dataloader['dataset']['data_root']   = ProstateMRI_dataset_folder\n",
        "cfg.test_dataloader['dataset']['data_root']  = ProstateMRI_dataset_folder\n",
        "\n",
        "cfg.visualizer['save_dir'] = results_folder\n",
        "cfg.visualizer['vis_backends'] = [\n",
        "    dict(type='LocalVisBackend'),\n",
        "    dict(type='TensorboardVisBackend')\n",
        "]\n",
        "\n",
        "cfg.visualizer['save_dir'] = results_folder\n",
        "cfg.visualizer['vis_backends'] = [\n",
        "    dict(type='LocalVisBackend'),\n",
        "    dict(type='TensorboardVisBackend')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYsb0pqnXJLN"
      },
      "outputs": [],
      "source": [
        "# PreProcessing Transform Class Creation\n",
        "\n",
        "from skimage import util\n",
        "import skimage.exposure as exposure\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "\n",
        "from mmcv.transforms import BaseTransform, TRANSFORMS\n",
        "import mmseg.datasets.transforms as mmsegTransforms\n",
        "\n",
        "@TRANSFORMS.register_module()\n",
        "class PreProcessing(BaseTransform):\n",
        "\n",
        "    # Initialization of the class\n",
        "    def __init__(self,\n",
        "                EqualizzazioneIstogrammaFlagADC, EqualizzazioneIstogrammaFlagHBV, EqualizzazioneIstogrammaFlagT2W,\n",
        "                FiltraggioGaussianoFlagADC, FiltraggioGaussianoFlagHBV, FiltraggioGaussianoFlagT2W, sigmaADC, sigmaHBV, sigmaT2W,\n",
        "                ModificaContrastoFlagADC, ModificaContrastoFlagHBV, ModificaContrastoFlagT2W, percContrADC, percContrHBV, percContrT2W,\n",
        "                MinMaxScalingFlagADC, MinMaxScalingFlagHBV, MinMaxScalingFlagT2W\n",
        "                ):\n",
        "        super().__init__()\n",
        "        # Gaussian filtering\n",
        "        self.FiltraggioGaussianoFlagADC = FiltraggioGaussianoFlagADC\n",
        "        self.FiltraggioGaussianoFlagHBV = FiltraggioGaussianoFlagHBV\n",
        "        self.FiltraggioGaussianoFlagT2W = FiltraggioGaussianoFlagT2W\n",
        "        self.sigmaADC = sigmaADC\n",
        "        self.sigmaHBV = sigmaHBV\n",
        "        self.sigmaT2W = sigmaT2W\n",
        "        # Histogram equalization\n",
        "        self.EqualizzazioneIstogrammaFlagADC = EqualizzazioneIstogrammaFlagADC\n",
        "        self.EqualizzazioneIstogrammaFlagHBV = EqualizzazioneIstogrammaFlagHBV\n",
        "        self.EqualizzazioneIstogrammaFlagT2W = EqualizzazioneIstogrammaFlagT2W\n",
        "        # Contrast modification\n",
        "        self.ModificaContrastoFlagADC = ModificaContrastoFlagADC\n",
        "        self.ModificaContrastoFlagHBV = ModificaContrastoFlagHBV\n",
        "        self.ModificaContrastoFlagT2W = ModificaContrastoFlagT2W\n",
        "        self.percContrADC = percContrADC\n",
        "        self.percContrHBV = percContrHBV\n",
        "        self.percContrT2W = percContrT2W\n",
        "        # Min-Max Scaling\n",
        "        self.MinMaxScalingFlagADC = MinMaxScalingFlagADC\n",
        "        self.MinMaxScalingFlagHBV = MinMaxScalingFlagHBV\n",
        "        self.MinMaxScalingFlagT2W = MinMaxScalingFlagT2W\n",
        "\n",
        "    # Adaptive histogram equalization\n",
        "    def EqualizzazioneIstogramma(self, img):\n",
        "        img = exposure.equalize_adapthist(img)\n",
        "        return img\n",
        "\n",
        "    # Gaussian Filter\n",
        "    def FiltraggioGaussiano(self, img, sigma):\n",
        "        img = ndimage.gaussian_filter(img, sigma)\n",
        "        return img\n",
        "\n",
        "    # Contrast Modification\n",
        "    def ModificaContrasto(self, img, percContr):\n",
        "        img = util.img_as_float(img)\n",
        "        luminanza = np.sum(img)/img.size\n",
        "        diff = img-luminanza\n",
        "        img = img + diff*percContr/100\n",
        "        img = np.clip(img,0,1)\n",
        "        return img\n",
        "\n",
        "    # Min-Max Scaling\n",
        "    def MinMaxScaling(self, img):\n",
        "        if img.max() == img.min():\n",
        "            return img\n",
        "        else:\n",
        "            img = (img - img.min()) / (img.max() - img.min())\n",
        "            return img\n",
        "\n",
        "\n",
        "    # uint8 Conversion\n",
        "    def uint8Conversion(self, img):\n",
        "        img = util.img_as_ubyte(img)\n",
        "        return img\n",
        "\n",
        "    # Application of transformations\n",
        "    def transform(self, results: dict) -> dict:\n",
        "        img = results['img']\n",
        "\n",
        "        # Application of transformations to each image channel\n",
        "        for i in range(img.shape[2]):\n",
        "            channel_img = img[:,:,i]\n",
        "\n",
        "            if i == 0:  # Apply preprocessing to ADC channel\n",
        "                channel_img = self.FiltraggioGaussiano(channel_img, self.sigmaADC) if self.FiltraggioGaussianoFlagADC else channel_img\n",
        "                channel_img = self.EqualizzazioneIstogramma(channel_img) if self.EqualizzazioneIstogrammaFlagADC else channel_img\n",
        "                channel_img = self.ModificaContrasto(channel_img, self.percContrADC) if self.ModificaContrastoFlagADC else channel_img\n",
        "                channel_img = self.MinMaxScaling(channel_img) if self.MinMaxScalingFlagADC else channel_img\n",
        "                channel_img = self.uint8Conversion(channel_img)\n",
        "\n",
        "            elif i == 1:  # Apply different preprocessing HBV channel\n",
        "                channel_img = self.FiltraggioGaussiano(channel_img, self.sigmaHBV) if self.FiltraggioGaussianoFlagHBV else channel_img\n",
        "                channel_img = self.EqualizzazioneIstogramma(channel_img) if self.EqualizzazioneIstogrammaFlagHBV else channel_img\n",
        "                channel_img = self.ModificaContrasto(channel_img, self.percContrHBV) if self.ModificaContrastoFlagHBV else channel_img\n",
        "                channel_img = self.MinMaxScaling(channel_img) if self.MinMaxScalingFlagHBV else channel_img\n",
        "                channel_img = self.uint8Conversion(channel_img)\n",
        "\n",
        "            else:  # Apply different preprocessing T2W channel\n",
        "                channel_img = self.FiltraggioGaussiano(channel_img, self.sigmaT2W) if self.FiltraggioGaussianoFlagT2W else channel_img\n",
        "                channel_img = self.EqualizzazioneIstogramma(channel_img) if self.EqualizzazioneIstogrammaFlagT2W else channel_img\n",
        "                channel_img = self.ModificaContrasto(channel_img, self.percContrT2W) if self.ModificaContrastoFlagT2W else channel_img\n",
        "                channel_img = self.MinMaxScaling(channel_img) if self.MinMaxScalingFlagT2W else channel_img\n",
        "                channel_img = self.uint8Conversion(channel_img)\n",
        "\n",
        "            img[:,:,i] = channel_img\n",
        "\n",
        "        results['img'] = img\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffkFV_6nW4dd"
      },
      "outputs": [],
      "source": [
        "# Preprocessing for ADC channel\n",
        "FiltraggioGaussianoFlagADC, sigmaADC = False, 1.5\n",
        "EqualizzazioneIstogrammaFlagADC = False\n",
        "ModificaContrastoFlagADC, percContrADC = False, 50\n",
        "MinMaxScalingFlagADC = True\n",
        "\n",
        "# Preprocessing for HBV channel\n",
        "FiltraggioGaussianoFlagHBV, sigmaHBV = False, 1.5\n",
        "EqualizzazioneIstogrammaFlagHBV = False\n",
        "ModificaContrastoFlagHBV, percContrHBV = False, 50\n",
        "MinMaxScalingFlagHBV = True\n",
        "\n",
        "# Preprocessing for T2W channel\n",
        "FiltraggioGaussianoFlagT2W, sigmaT2W = False, 1.5\n",
        "EqualizzazioneIstogrammaFlagT2W = False\n",
        "ModificaContrastoFlagT2W, percContrT2W = False, 50\n",
        "MinMaxScalingFlagT2W = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "325RRmiwW69h"
      },
      "outputs": [],
      "source": [
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='PreProcessing',\n",
        "         FiltraggioGaussianoFlagADC=FiltraggioGaussianoFlagADC, sigmaADC=sigmaADC,\n",
        "         EqualizzazioneIstogrammaFlagADC=EqualizzazioneIstogrammaFlagADC,\n",
        "         ModificaContrastoFlagADC=ModificaContrastoFlagADC, percContrADC=percContrADC,\n",
        "         MinMaxScalingFlagADC=MinMaxScalingFlagADC,\n",
        "         FiltraggioGaussianoFlagHBV=FiltraggioGaussianoFlagHBV, sigmaHBV=sigmaHBV,\n",
        "         EqualizzazioneIstogrammaFlagHBV=EqualizzazioneIstogrammaFlagHBV,\n",
        "         ModificaContrastoFlagHBV=ModificaContrastoFlagHBV, percContrHBV=percContrHBV,\n",
        "\n",
        "         MinMaxScalingFlagHBV=MinMaxScalingFlagHBV,\n",
        "         FiltraggioGaussianoFlagT2W=FiltraggioGaussianoFlagT2W, sigmaT2W=sigmaT2W,\n",
        "         EqualizzazioneIstogrammaFlagT2W=EqualizzazioneIstogrammaFlagT2W,\n",
        "         ModificaContrastoFlagT2W=ModificaContrastoFlagT2W, percContrT2W=percContrT2W,\n",
        "         MinMaxScalingFlagT2W=MinMaxScalingFlagT2W),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(prob=0.5, type='RandomFlip'),\n",
        "    dict(degree=(-15.0,15.0), prob=0.5, type='RandomRotate'),\n",
        "    dict(type='PackSegInputs'),\n",
        "]\n",
        "\n",
        "cfg.train_dataloader.dataset.pipeline= cfg.train_pipeline\n",
        "\n",
        "cfg.val_dataloader.dataset.pipeline =[\n",
        "            dict(type='LoadImageFromFile'),\n",
        "            dict(type='PreProcessing',\n",
        "                FiltraggioGaussianoFlagADC=FiltraggioGaussianoFlagADC, sigmaADC=sigmaADC,\n",
        "                EqualizzazioneIstogrammaFlagADC=EqualizzazioneIstogrammaFlagADC,\n",
        "                ModificaContrastoFlagADC=ModificaContrastoFlagADC, percContrADC=percContrADC,\n",
        "                MinMaxScalingFlagADC=MinMaxScalingFlagADC,\n",
        "                FiltraggioGaussianoFlagHBV=FiltraggioGaussianoFlagHBV, sigmaHBV=sigmaHBV,\n",
        "                EqualizzazioneIstogrammaFlagHBV=EqualizzazioneIstogrammaFlagHBV,\n",
        "                ModificaContrastoFlagHBV=ModificaContrastoFlagHBV, percContrHBV=percContrHBV,\n",
        "                MinMaxScalingFlagHBV=MinMaxScalingFlagHBV,\n",
        "                FiltraggioGaussianoFlagT2W=FiltraggioGaussianoFlagT2W, sigmaT2W=sigmaT2W,\n",
        "                EqualizzazioneIstogrammaFlagT2W=EqualizzazioneIstogrammaFlagT2W,\n",
        "                ModificaContrastoFlagT2W=ModificaContrastoFlagT2W, percContrT2W=percContrT2W,\n",
        "                MinMaxScalingFlagT2W=MinMaxScalingFlagT2W),\n",
        "            dict(type='LoadAnnotations'),\n",
        "            dict(type='PackSegInputs'),\n",
        "        ]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='PackSegInputs'),\n",
        "]\n",
        "\n",
        "cfg.test_dataloader.dataset.pipeline = cfg.test_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SfiJ4cgYBSx"
      },
      "outputs": [],
      "source": [
        "# Epoch Runner (instead of Iteration Runner)\n",
        "# Parameters of config files changed according to MMSegmentation tutorial in order to use the Epoch Runner instead of the Iteration Runner\n",
        "\n",
        "cfg.param_scheduler = dict(\n",
        "    by_epoch=True,\n",
        "    milestones=[6, 8],\n",
        "    type='MultiStepLR'\n",
        ")\n",
        "\n",
        "cfg.default_hooks.logger.log_metric_by_epoch = True\n",
        "cfg.default_hooks.checkpoint=dict(type='CheckpointHook', interval=5, by_epoch=True)\n",
        "\n",
        "cfg.train_cfg = dict(by_epoch=True, max_epochs=50, val_interval=2) # by_epoch=True or type='EpochBasedTrainLoop'instead of type='IterBasedTrainLoop'\n",
        "\n",
        "cfg.log_processor = dict(by_epoch=True)\n",
        "\n",
        "cfg.train_dataloader.sampler = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz6jFvBpETYZ"
      },
      "source": [
        "## **Hyperparameter Modification + Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHURwKBJETYZ"
      },
      "source": [
        "**Net Changes**: write here things to change and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpuoJU7cBT70"
      },
      "outputs": [],
      "source": [
        "# Batch Size\n",
        "cfg.train_dataloader['batch_size'] = 8\n",
        "\n",
        "# Loss Function\n",
        "cfg.model.decode_head.loss_decode=dict(type='TverskyLoss', alpha=0.3, beta=0.7)\n",
        "\n",
        "# Backbone Strides\n",
        "# cfg.model.backbone.strides = (1, 1, 1, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i1bTk1zm04X"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjgE6MbUW8Ye"
      },
      "outputs": [],
      "source": [
        "# Build Runner\n",
        "from mmengine.runner import Runner\n",
        "runner = Runner.from_cfg(cfg)\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqpT5aETcstX"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpgNsNGxEJpr"
      },
      "outputs": [],
      "source": [
        "# Start testing\n",
        "# runner.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2rWApDHY_C_"
      },
      "source": [
        "## **Volumetric Inference**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Unzip test set zip: it's organized as the available dataset and as the test set blind**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsVvbB44ZCeA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "\n",
        "from mmseg.apis import init_model, inference_model, show_result_pyplot\n",
        "import mmcv\n",
        "\n",
        "# Test Set Path Definition\n",
        "testSetZipPath = os.path.join('/content/drive/MyDrive/Progetto EIM/volumetricTestSet.zip')\n",
        "\n",
        "testSetPath = os.path.join('/content/testSet/')\n",
        "\n",
        "# Unzip\n",
        "with ZipFile(testSetZipPath, 'r') as zip_ref:\n",
        "    # Get the total number of files in the zip file\n",
        "    total_files = len(zip_ref.infolist())\n",
        "\n",
        "    # Create a progress bar using tqdm\n",
        "    with tqdm(total=total_files, unit=\"file\") as pbar:\n",
        "        for member in zip_ref.infolist():\n",
        "            # Extract each file individually and update the progress bar\n",
        "            zip_ref.extract(member, testSetPath)\n",
        "            pbar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Definition of PreProcessing Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOvTqsOfbCgC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "def findBorders(t2w):\n",
        "    # FIND BLACK BORDERS IN T2W CHANNEL\n",
        "    # Make t2w boolean\n",
        "    t2w_bool = t2w > 0\n",
        "    # Find non-black rows and columns\n",
        "    rows = np.any(t2w_bool, axis=1)\n",
        "    cols = np.any(t2w_bool, axis=0)\n",
        "    # Get first and last non-black row and column indexes\n",
        "    rmin, rmax = np.where(rows)[0][[0, -1]] if np.any(rows) else (0, t2w.shape[0])\n",
        "    cmin, cmax = np.where(cols)[0][[0, -1]] if np.any(cols) else (0, t2w.shape[1])\n",
        "    return rmin, rmax, cmin, cmax\n",
        "\n",
        "def cropResizeImages(adc, hbv, t2w):\n",
        "    # CROP IMAGES\n",
        "    # Get original image size\n",
        "    original_shape = t2w.shape\n",
        "    # Find black borders in t2w channel\n",
        "    rmin_t2w, rmax_t2w, cmin_t2w, cmax_t2w = findBorders(t2w)\n",
        "    # Get final cropped image size\n",
        "    cropDimension = min(rmax_t2w - rmin_t2w, cmax_t2w - cmin_t2w)\n",
        "    if cropDimension % 2 != 0: # ensure crop_size is even\n",
        "        cropDimension -= 1\n",
        "    if abs(t2w.shape[0] - cropDimension) < 5: # do not crop if the black region is too small\n",
        "        cropDimension = t2w.shape[0]\n",
        "        flagCrop = False\n",
        "        # resize images to 256x256\n",
        "        resizeShape = (256, 256)\n",
        "        adc_resized = np.array(Image.fromarray(adc, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
        "        hbv_resized = np.array(Image.fromarray(hbv, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
        "        t2w_resized = np.array(Image.fromarray(t2w, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
        "        # Create the dictionary to store resize metadata\n",
        "        cropMetadata = {'flagCrop': flagCrop, 'original_shape': original_shape, 'resizeShape': resizeShape, 'cropDimension': cropDimension}\n",
        "        return adc_resized, hbv_resized, t2w_resized, cropMetadata\n",
        "    else:\n",
        "        flagCrop = True\n",
        "\n",
        "    # Get center of the non-black region\n",
        "    center_x = (cmin_t2w + cmax_t2w) // 2\n",
        "    center_y = (rmin_t2w + rmax_t2w) // 2\n",
        "    # Get start and end coordinates for cropping\n",
        "    start_x = max(center_x - cropDimension // 2, 0)\n",
        "    start_y = max(center_y - cropDimension // 2, 0)\n",
        "    end_x = min(start_x + cropDimension, t2w.shape[1])\n",
        "    end_y = min(start_y + cropDimension, t2w.shape[0])\n",
        "\n",
        "    # Crop images at the center of the non-black region\n",
        "    adc_cropped = adc[start_y:end_y, start_x:end_x]\n",
        "    hbv_cropped = hbv[start_y:end_y, start_x:end_x]\n",
        "    t2w_cropped = t2w[start_y:end_y, start_x:end_x]\n",
        "\n",
        "    cropped_shape = t2w_cropped.shape\n",
        "\n",
        "    # RESIZE IMAGES\n",
        "    # Resize cropped images to 256x256\n",
        "    resizeShape = (256, 256)\n",
        "    adc_cropped_resized = np.array(Image.fromarray(adc_cropped, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
        "    hbv_cropped_resized = np.array(Image.fromarray(hbv_cropped, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
        "    t2w_cropped_resized = np.array(Image.fromarray(t2w_cropped, mode='L').resize(resizeShape, Image.LANCZOS), dtype=np.uint8)\n",
        "\n",
        "    # Create a dictionary to store crop metadata\n",
        "    cropMetadata = {'start_x': start_x, 'start_y': start_y, 'end_x': end_x, 'end_y': end_y, 'cropDimension': cropDimension, 'cropped_shape': cropped_shape, 'center_x': center_x, 'center_y': center_y, 'original_shape': original_shape, 'resizeShape': resizeShape, 'flagCrop': flagCrop}\n",
        "\n",
        "    return adc_cropped_resized, hbv_cropped_resized, t2w_cropped_resized, cropMetadata\n",
        "\n",
        "def restoreSizeMask(mask, cropMetadata):\n",
        "    # RESTORE AUTOMATIC MASK TO ORIGINAL SIZE\n",
        "    # Check if the image was not cropped\n",
        "    if not cropMetadata['flagCrop']:\n",
        "        mask_restored = np.array(Image.fromarray(mask, mode='L').resize(cropMetadata['original_shape'], Image.NEAREST), dtype=np.uint8)\n",
        "        return mask_restored\n",
        "\n",
        "    else:\n",
        "        mask_restored = np.zeros(cropMetadata['original_shape'], dtype=np.uint8)\n",
        "        mask_cropDim = np.array(Image.fromarray(mask, mode='L').resize(cropMetadata['cropped_shape'], Image.NEAREST), dtype=np.uint8)\n",
        "        mask_restored[cropMetadata['start_y']:cropMetadata['end_y'], cropMetadata['start_x']:cropMetadata['end_x']] = mask_cropDim\n",
        "\n",
        "        return mask_restored\n",
        "\n",
        "def minMaxScaling(img):\n",
        "    if np.max(img) != np.min(img):\n",
        "        img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
        "        img = np.array(img*255, dtype=np.uint8)\n",
        "\n",
        "    return img\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Definition of PostProcessing Function (Interpolation)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loe3vZLTbDQr"
      },
      "outputs": [],
      "source": [
        "# Definition of Function for Interpolation between two masks\n",
        "from scipy.ndimage import distance_transform_edt\n",
        "\n",
        "def interp_mask(mask1, mask2):\n",
        "    \n",
        "    d1 = distance_transform_edt(mask1) - distance_transform_edt(~mask1)\n",
        "    d2 = distance_transform_edt(mask2) - distance_transform_edt(~mask2)\n",
        "    interpolated_mask=(d1+d2) > 0\n",
        "    interpolated_mask = np.array(interpolated_mask, dtype=np.uint8)\n",
        "\n",
        "    return interpolated_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnMTYxH8bIHa"
      },
      "outputs": [],
      "source": [
        "# Loop over the test images\n",
        "checkpoint_path = os.path.join(results_folder, 'epoch_50.pth')\n",
        "model = init_model(cfg, checkpoint_path, 'cuda:0')\n",
        "\n",
        "\n",
        "patientList = os.listdir(testSetPath)\n",
        "# Initialize a dict to store cropDimension metadata\n",
        "cropDimensionList = {}\n",
        "contatoreMaskDaInterpolare = 0\n",
        "\n",
        "\n",
        "for patient in tqdm(patientList):\n",
        "\n",
        "  # Create a dictionary key of the patient name\n",
        "  cropDimensionList[patient] = {}\n",
        "\n",
        "  os.makedirs(os.path.join(testSetPath, patient, \"automatic\"), exist_ok=True)\n",
        "\n",
        "  sliceList = os.listdir(os.path.join(testSetPath, patient, \"stacked\"))\n",
        "\n",
        "  # Initialization of elements needed for post-processing\n",
        "  tumorVolume = 0\n",
        "  numTumoralSlices = 0\n",
        "  hasTumor = False\n",
        "  listTumoralSlices = []\n",
        "\n",
        "\n",
        "  for slice in sliceList:\n",
        "    if slice.endswith('.png'):\n",
        "\n",
        "      ###############################\n",
        "      #######      Load      ########\n",
        "      ###############################\n",
        "\n",
        "      # adc_path = os.path.join(test_img_folder, patient, \"adc\", slice)\n",
        "      # hbv_path = os.path.join(test_img_folder, patient, \"hbv\", slice)\n",
        "      # t2w_path = os.path.join(test_img_folder, patient, \"t2w\", slice)\n",
        "\n",
        "      # adc = np.array(Image.open(adc_path))\n",
        "      # hbv = np.array(Image.open(hbv_path))\n",
        "      # t2w = np.array(Image.open(t2w_path))\n",
        "\n",
        "      stacked_path = os.path.join(testSetPath, patient, \"stacked\", slice)\n",
        "\n",
        "      stacked = np.array(Image.open(stacked_path))\n",
        "\n",
        "      adc = stacked[:,:,0]\n",
        "      hbv = stacked[:,:,1]\n",
        "      t2w = stacked[:,:,2]\n",
        "\n",
        "      ###############################\n",
        "      ####### Pre-Processing ########\n",
        "      ###############################\n",
        "\n",
        "      # Crop\n",
        "      adc, hbv, t2w, cropMetadata = cropResizeImages(adc, hbv, t2w)\n",
        "\n",
        "      # Store cropDimension metadata in the dictionary list\n",
        "      cropDimensionList[patient][slice] = cropMetadata['cropDimension']\n",
        "\n",
        "      # Min-Max Scaling\n",
        "      adc = minMaxScaling(adc)\n",
        "      hbv = minMaxScaling(hbv)\n",
        "      t2w = minMaxScaling(t2w)\n",
        "\n",
        "      # Stack the images\n",
        "      stacked = np.stack((adc, hbv, t2w), axis=-1)\n",
        "\n",
        "      ###############################\n",
        "      #######    Inference   ########\n",
        "      ###############################\n",
        "\n",
        "      result = inference_model(model, stacked)\n",
        "\n",
        "      # Get data from the result\n",
        "      pred_label = result.pred_sem_seg.data.squeeze()\n",
        "      pred_label = pred_label.cpu().numpy().astype(np.uint8)\n",
        "\n",
        "      ###############################\n",
        "      ### Computation of elements ###\n",
        "      ###       needed for        ###\n",
        "      ###     post-processing     ###\n",
        "      ###############################\n",
        "\n",
        "      # Computation of elements needed for post-processing\n",
        "      if np.sum(pred_label) > 0:\n",
        "          hasTumor = True\n",
        "          numTumoralSlices += 1\n",
        "          tumorVolume += np.sum(pred_label.astype(bool))\n",
        "          listTumoralSlices.append(slice)\n",
        "\n",
        "      ###############################\n",
        "      #######   Save results  #######\n",
        "      ###############################\n",
        "\n",
        "      # Restore the original size\n",
        "      # pred_label = np.array(pred_label)\n",
        "      pred_label = restoreSizeMask(pred_label, cropMetadata)\n",
        "      pred_label = np.array(pred_label, dtype=np.uint8)\n",
        "\n",
        "      # Save the result\n",
        "      pred_label = Image.fromarray(pred_label, mode='L')\n",
        "\n",
        "      pred_label.save(os.path.join(testSetPath, patient, \"automatic\", slice))\n",
        "\n",
        "\n",
        "  ###############################\n",
        "  ####### Post-Processing #######\n",
        "  ###############################\n",
        "\n",
        "\n",
        "#   if hasTumor:\n",
        "#     exampleSliceStacked = np.array(Image.open(os.path.join(testSetPath, patient, \"stacked\", sliceList[0])))\n",
        "#     exampleSlice = exampleSliceStacked[:,:,0]\n",
        "#     shapeSlices = exampleSlice.shape\n",
        "\n",
        "#     # # Check tumor volume\n",
        "#     # if tumorVolume < 13:\n",
        "#     #   blackMask = Image.fromarray(np.zeros((shapeSlices[0], shapeSlices[1]), dtype=np.uint8)).convert('L')\n",
        "#     #   for slice in sliceList:\n",
        "#     #     if slice.endswith('.png'):\n",
        "#     #       blackMask.save(os.path.join(testSetPath, patient, \"automatic\", slice))\n",
        "\n",
        "#     # # Check number of tumoral slices\n",
        "#     # if numTumoralSlices == 1:\n",
        "#     #   blackMask = Image.fromarray(np.zeros((shapeSlices[0], shapeSlices[1]), dtype=np.uint8)).convert('L')\n",
        "#     #   for slice in sliceList:\n",
        "#     #     if slice.endswith('.png'):\n",
        "#     #       blackMask.save(os.path.join(testSetPath, patient, \"automatic\", slice))\n",
        "\n",
        "#     # Check if there are black slices between two tumoral slices --> if so, interpolate all the black slices with the tumoral slices before and after\n",
        "#     # Set a maximum number of black slices to look for between two tumoral slices\n",
        "#     maxBlackSlices = 100\n",
        "#     listTumoralSlices.sort()\n",
        "#     # Extract the number of the tumoral slices from the list. They are called slice_n.png\n",
        "#     listTumoralSlices = [int(slice.split('.')[0].split('_')[1]) for slice in listTumoralSlices]\n",
        "#     # Check how many black slices there are between two tumoral slices using difference between consecutive elements\n",
        "#     diffTumoralSlices = np.diff(listTumoralSlices) - 1\n",
        "#     for i in range(len(diffTumoralSlices)):\n",
        "#       if diffTumoralSlices[i] > 0:\n",
        "#         if diffTumoralSlices[i] <= maxBlackSlices:\n",
        "#           for j in range(1, diffTumoralSlices[i]+1):\n",
        "#             contatoreMaskDaInterpolare += 1\n",
        "#             # interpolate the mask of the black slice with interp_shape function\n",
        "#             top = np.array(Image.open(os.path.join(testSetPath, patient, \"automatic\", f\"slice_{listTumoralSlices[i]}.png\")))\n",
        "#             bottom = np.array(Image.open(os.path.join(testSetPath, patient, \"automatic\", f\"slice_{listTumoralSlices[i+1]}.png\")))\n",
        "#             black = interp_shape(top, bottom, 0.5)\n",
        "#             black = Image.fromarray(black, mode='L')\n",
        "\n",
        "#             black = interp_mask(top, bottom)\n",
        "#             black = Image.fromarray(black*255, mode='L')\n",
        "#             black.save(os.path.join(testSetPath, patient, \"automatic\", f\"slice_{listTumoralSlices[i]+j}.png\"))\n",
        "\n",
        "# print(f\"Numero di maschere da interpolare: {contatoreMaskDaInterpolare}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Metrics Computation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjH4lmvebwlm"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "patientsList = os.listdir(testSetPath)\n",
        "\n",
        "# Initialization of evaluation metrics\n",
        "DiceList = []\n",
        "\n",
        "DiffVolumeList = []\n",
        "AbsErrorList = []\n",
        "RelDiffVolumeList = []\n",
        "\n",
        "HausdorffDistanceList = []\n",
        "\n",
        "tumPatientTP = 0\n",
        "hltPatientTN = 0\n",
        "tumPatientTotal = 0\n",
        "hltPatientTotal = 0\n",
        "\n",
        "# Loop over the patients\n",
        "for patient in tqdm(patientsList):\n",
        "  # Get the list of slices\n",
        "  sliceList = os.listdir(os.path.join(testSetPath, patient, \"stacked\"))\n",
        "  # Get the shape of the patient's slices\n",
        "  exampleSlicePath = os.path.join(testSetPath, patient, \"manual\", sliceList[0])\n",
        "  exampleSlice = np.array(Image.open(exampleSlicePath))\n",
        "  shapeSlice = exampleSlice.shape\n",
        "\n",
        "  # Initialization of 3D masks\n",
        "  ManMask3D_bool = np.zeros((shapeSlice[0], shapeSlice[1], len(sliceList)), dtype=bool)\n",
        "  AutoMask3D_bool = np.zeros((shapeSlice[0], shapeSlice[1], len(sliceList)), dtype=bool)\n",
        "\n",
        "  # Initialization of lists to store 3D contour points (for HD)\n",
        "  contourPoints3D_Man = []\n",
        "  contourPoints3D_Auto = []\n",
        "\n",
        "  # Loop over the slices to create 3D masks\n",
        "  for actSlice in sliceList:\n",
        "    actManMask = os.path.join(testSetPath, patient, \"manual\", actSlice)\n",
        "    actAutoMask = os.path.join(testSetPath, patient, \"automatic\", actSlice)\n",
        "\n",
        "    ManMask3D_bool[:,:,sliceList.index(actSlice)] = np.array(Image.open(os.path.join(testSetPath, patient, \"manual\", actSlice))).astype(bool)\n",
        "    AutoMask3D_bool[:,:,sliceList.index(actSlice)] = np.array(Image.open(os.path.join(testSetPath, patient, \"automatic\", actSlice))).astype(bool)\n",
        "\n",
        "\n",
        "  # CALCULATION OF EVALUATION METRICS\n",
        "  # Calculation of elements necessary for the calculation of metrics\n",
        "  # For Dice\n",
        "  TPmask = np.sum(ManMask3D_bool & AutoMask3D_bool)\n",
        "  FPmask = np.sum(~ManMask3D_bool & AutoMask3D_bool)\n",
        "  TNmask = np.sum(~ManMask3D_bool & ~AutoMask3D_bool)\n",
        "  FNmask = np.sum(ManMask3D_bool & ~AutoMask3D_bool)\n",
        "\n",
        "  # For Volume-based metrics\n",
        "  totalVolumeMan = np.sum(ManMask3D_bool)\n",
        "  totalVolumeAuto = np.sum(AutoMask3D_bool)\n",
        "  diffVolume = totalVolumeMan - totalVolumeAuto\n",
        "\n",
        "  # For Hausdorff Distance\n",
        "  ManMask3D_uint8 = ManMask3D_bool.astype(np.uint8)*255\n",
        "  AutoMask3D_uint8 = AutoMask3D_bool.astype(np.uint8)*255\n",
        "  for s in range(len(ManMask3D_uint8[0,0,:])):\n",
        "    actManMask = ManMask3D_uint8[:,:,s]\n",
        "    actAutoMask = AutoMask3D_uint8[:,:,s]\n",
        "\n",
        "    contours_Man = cv2.findContours(actManMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours_Auto = cv2.findContours(actAutoMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for contour in contours_Man[0]:\n",
        "      for point in contour:\n",
        "        contourPoints3D_Man.append([point[0][0], point[0][1], s])\n",
        "    for contour in contours_Auto[0]:\n",
        "      for point in contour:\n",
        "        contourPoints3D_Auto.append([point[0][0], point[0][1], s])\n",
        "\n",
        "  # Dice\n",
        "  if (2*TPmask + FPmask + FNmask)!=0:\n",
        "    Dice = 2*TPmask/(2*TPmask + FPmask + FNmask)\n",
        "    DiceList.append(Dice)\n",
        "\n",
        "  # Volume-based\n",
        "  DiffVolumePaziente = diffVolume\n",
        "  DiffVolumeList.append(DiffVolumePaziente)\n",
        "\n",
        "  AbsErrorPaziente = abs(DiffVolumePaziente)\n",
        "  AbsErrorList.append(AbsErrorPaziente)\n",
        "\n",
        "  if totalVolumeMan != 0:\n",
        "    RelDiffVolume = diffVolume / totalVolumeMan\n",
        "    RelDiffVolumeList.append(RelDiffVolume)\n",
        "  elif totalVolumeMan == 0 and totalVolumeAuto != 0:\n",
        "    pass\n",
        "  else:\n",
        "    RelDiffVolumeList.append(0)\n",
        "  \n",
        "  # Hausdorff Distance\n",
        "  if contourPoints3D_Man and contourPoints3D_Auto:\n",
        "    HausdorffDistance = max(directed_hausdorff(contourPoints3D_Man, contourPoints3D_Auto)[0], directed_hausdorff(contourPoints3D_Auto, contourPoints3D_Man)[0])\n",
        "    HausdorffDistance = HausdorffDistance / np.mean(list(cropDimensionList[patient].values())) * 256 # normalize HD as explained in the report\n",
        "    HausdorffDistanceList.append(HausdorffDistance)\n",
        "\n",
        "  # Sensibility e Specificity\n",
        "  if np.sum(ManMask3D_bool) > 0 and np.sum(AutoMask3D_bool) > 0:\n",
        "    tumPatientTP += 1\n",
        "  elif np.sum(ManMask3D_bool) == 0 and np.sum(AutoMask3D_bool) == 0:\n",
        "    hltPatientTN += 1\n",
        "  if np.sum(ManMask3D_bool) > 0:\n",
        "    tumPatientTotal += 1\n",
        "  else:\n",
        "    hltPatientTotal += 1\n",
        "\n",
        "# MEAN AND STD OF EVALUATION METRICS\n",
        "MeanDice = np.mean(DiceList)\n",
        "StdDice = np.std(DiceList)\n",
        "print(f\"\\nDice: {MeanDice:.2f} +- {StdDice:.2f} (Mean +- Std)\")\n",
        "\n",
        "MeanDiffVolume = np.mean(DiffVolumeList)\n",
        "MeanAbsError = np.mean(AbsErrorList)\n",
        "MeanRelDiffVolume = np.mean(RelDiffVolumeList)\n",
        "\n",
        "StdDiffVolume = np.std(DiffVolumeList)\n",
        "StdAbsError = np.std(AbsErrorList)\n",
        "StdRelDiffVolume = np.std(RelDiffVolumeList)\n",
        "\n",
        "print(f\"DiffVolume: {MeanDiffVolume:.2f} +- {StdDiffVolume:.2f} (Mean +- Std)\")\n",
        "print(f\"AbsError: {MeanAbsError:.2f} +- {StdAbsError:.2f} (Mean +- Std)\")\n",
        "print(f\"RelDiffVolume: {MeanRelDiffVolume:.2f} +- {StdRelDiffVolume:.2f} (Mean +- Std)\")\n",
        "\n",
        "MeanHausdorffDistance = np.mean(HausdorffDistanceList)\n",
        "StdHausdorffDistance = np.std(HausdorffDistanceList)\n",
        "print(f\"Hausdorff Distance: {MeanHausdorffDistance:.2f} +- {StdHausdorffDistance:.2f} (Mean +- Std)\")\n",
        "\n",
        "if tumPatientTotal > 0:\n",
        "  Sensibility = 100 * tumPatientTP / tumPatientTotal\n",
        "else:\n",
        "  Sensibility = 100\n",
        "\n",
        "if hltPatientTotal > 0:\n",
        "  Specificity = 100 * hltPatientTN / hltPatientTotal\n",
        "else:\n",
        "  Specificity = 100\n",
        "\n",
        "print(f\"SensibilityTum: {Sensibility:.2f}%\")\n",
        "print(f\"SpecificitySani: {Specificity:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_WoGAzCI3_a"
      },
      "source": [
        "## **Plot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI4lMHZkuBp0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact\n",
        "\n",
        "# Definition of function to load images\n",
        "def load_images(patient_id, slice_id):\n",
        "    stacked_path = os.path.join(testSetPath, patient_id, \"stacked\", f\"slice_{slice_id}.png\")\n",
        "    mask_path = os.path.join(testSetPath, patient_id, \"manual\", f\"slice_{slice_id}.png\")\n",
        "    auto_mask_path = os.path.join(testSetPath, patient_id, \"automatic\", f\"slice_{slice_id}.png\")\n",
        "\n",
        "    img = np.array(Image.open(stacked_path))\n",
        "    adc = img[:,:,0]\n",
        "    hbv = img[:,:,1]\n",
        "    t2w = img[:,:,2]\n",
        "    mask = np.array(Image.open(mask_path)) * 255\n",
        "    auto_mask = np.array(Image.open(auto_mask_path)) * 255\n",
        "\n",
        "    return adc, hbv, t2w, mask, auto_mask\n",
        "\n",
        "# Definition of function to display images in a subplot with matplotlib\n",
        "def display_images(patient_id, slice_id):\n",
        "    adc, hbv, t2w, mask, auto_mask = load_images(patient_id, slice_id)\n",
        "\n",
        "    fig, axs = plt.subplots(3, 2, figsize=(12, 12))\n",
        "\n",
        "    axs[0, 0].imshow(adc, cmap='gray')\n",
        "    axs[0, 0].imshow(mask, cmap='gray', alpha=0.2)\n",
        "    axs[0, 0].set_title('ADC with manual mask')\n",
        "    axs[0, 0].axis('off')\n",
        "\n",
        "    axs[0, 1].imshow(adc, cmap='gray')\n",
        "    axs[0, 1].imshow(auto_mask, cmap='gray', alpha=0.2)\n",
        "    axs[0, 1].set_title('ADC with automatic mask')\n",
        "    axs[0, 1].axis('off')\n",
        "\n",
        "    axs[1, 0].imshow(hbv, cmap='gray')\n",
        "    axs[1, 0].imshow(mask, cmap='gray', alpha=0.2)\n",
        "    axs[1, 0].set_title('HBV with manual mask')\n",
        "    axs[1, 0].axis('off')\n",
        "\n",
        "    axs[1, 1].imshow(hbv, cmap='gray')\n",
        "    axs[1, 1].imshow(auto_mask, cmap='gray', alpha=0.2)\n",
        "    axs[1, 1].set_title('HBV with automatic mask')\n",
        "    axs[1, 1].axis('off')\n",
        "\n",
        "    axs[2, 0].imshow(t2w, cmap='gray')\n",
        "    axs[2, 0].imshow(mask, cmap='gray', alpha=0.2)\n",
        "    axs[2, 0].set_title('T2W with manual mask')\n",
        "    axs[2, 0].axis('off')\n",
        "\n",
        "    axs[2, 1].imshow(t2w, cmap='gray')\n",
        "    axs[2, 1].imshow(auto_mask, cmap='gray', alpha=0.2)\n",
        "    axs[2, 1].set_title('T2W with automatic mask')\n",
        "    axs[2, 1].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Definition of function to get the maximum number of slices for a patient\n",
        "def max_slices_for_patient(patient_id):\n",
        "    stacked_path = os.path.join(testSetPath, patient_id, \"stacked\")\n",
        "    return len([name for name in os.listdir(stacked_path) if os.path.isfile(os.path.join(stacked_path, name))])\n",
        "\n",
        "# Get list of patients of the test set\n",
        "patients = sorted(os.listdir(testSetPath))\n",
        "\n",
        "# Create widgets for patient selection and slice selection\n",
        "patient_selector = widgets.Select(options=patients, description=\"Paziente:\")\n",
        "slice_slider = widgets.IntSlider(min=1, max=1, value=1, description=\"Slice:\")\n",
        "\n",
        "def update_slice_range(*args):\n",
        "    patient_id = patient_selector.value\n",
        "    max_slices = max_slices_for_patient(patient_id)\n",
        "    slice_slider.max = max_slices\n",
        "\n",
        "patient_selector.observe(update_slice_range, 'value')\n",
        "\n",
        "update_slice_range()\n",
        "\n",
        "@interact(patient_id=patient_selector, slice_id=slice_slider)\n",
        "def explore_data(patient_id, slice_id):\n",
        "    display_images(patient_id, str(slice_id))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "O_WoGAzCI3_a"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
